# 四子棋AI程序
UCT = MonteCarlo + Upper Confidence Bound

## 程序简介
重力四子棋是一款经典的棋类游戏。游戏双方分别持不同颜色的棋子，设A持白子，B持黑子，以某一方为先手依次落子。假设A为先手，落子规则如下：在M行N列的棋盘中，棋手每次只能在每一列当前的最底部落子。棋手的目标是在横向、纵向、两个斜向共四个方向中的任意一个方向上，使自己的棋子连成四个（或四个以上），并阻止对方达到同样的企图。先形成四连子的一方获胜，如果直到棋盘落满双方都没能达目标，则为平局。

本项目实现了一个四子棋的AI，当两个策略对弈时，棋盘的大小是随机的（宽、高在9至12之间），而且会随机生成不可落子的点。如下图中红叉所示，当一方在小黑点处落子时，下次该列的可落子位置将是小绿点处。

## 算法思路
α-β剪枝算法的难点在于估价函数的设计上，需要大量的先验知识。本项目采用了蒙特卡罗搜索树（MCTS）算法结合信心上限算法（UCB1），即信心上限树算法 (UCT) 完成四子棋AI。算法共包含四个基本步骤，分别为选择(Selection)、扩展(Expansion)、 模拟(Simulation)、回溯(Back propagation)。

图中的每个节点表示博弈过程的一个局面状态，每条边表示在父节点上采取一个行动，并得到子节点所对应的局面状态。这四个基本步骤依次执行，从而完成一次搜索，具体说来这四个步骤为：
1. 选择（Selection）：从根节点出发，在搜索树上自上而下选择UCB1的信心上界值最大的子节点（可落子但没有被访问的节点信心上界值为正无穷），直至找到当前最为紧迫的可扩展节点。可扩展节点 ⇔ 节点所对应的状态是非停止状态，且拥有未被访问过的子节点；
2. 扩展（Expansion）：在被选择的节点上扩展一个或多子节点；
3. 模拟（Simulation）：根据默认策略（Default Policity）在扩展出来的一个（或多个）子节点上执行蒙特卡洛棋局模拟，并确定的估计值；
4. 回溯（Back propagation）：根据模拟结果向上依次更新祖先节点的估计根据模拟结果向上依次更新祖先节点的估计值，并更新其状态。

执行上述搜索过程直到时间达到规定，然后在根节点的儿子中选择信心上界值最大的节点给出落子操作。

信心上限树算法（UCT）伪代码描述如下 ：
``` javascript
function UCTSEARCH(s0) {
    以状态s0创建根节点v0;
    while 尚未用完计算时长 do:
        v_l ← TREEPOLICY(v_0);
        ∆ ← DEFAULTPOLICY(s(v_l));
        BACKUP(v_l,∆);
    end while
    return a(BESTCHILD(v_0,0)) }

function TREEPOLICY(v) {
    while 节点v不是终止节点 do:
        if 节点v是可扩展的 then:
            return EXPAND(v)
        else:
            v ← BESTCHILD(v,c)
    return v }

function EXPAND(v) {
    选择行动a∈A(state(v))中尚未选择过的行动
    向节点v添加子节点v'
    return v' }

function BESTCHILD(v,c) {
    return [argmax]_(v'∈children of v) ((Q(v'))/(N(v')) + c*√((2ln(N(v)))/(N(v')))) }

function DEFAULTPOLICY(s) {
    while s不是终止状态 do:
        以等概率选择行动a∈A(s)
        s←f(s,a)
    return 状态s的收益 }

function BACKUP(v,Δ) {
    while v≠NULL do:
        N(v)←N(v)+1
        Q(v)←Q(v)+∆
        ∆←-∆
        v←v的父节点 }
```

## 算法实现

### 变量定义
本项目定义了两个类，分别是用来表示蒙特卡洛树上节点的```Node```类，和表示棋局情况的```State```类。

### 执行过程
本项目在```Strategy```中进行下棋的循环。通过调用```UCT```中的函数来实现下棋的过程。

#### ```Strategy```中的关键变量
1. 全局变量```state```来存储过程中不断变化的棋局
2. ```root```节点为以开始计算前的状态生成的节点
3. ```simulationNode```节点为模拟棋局过程中生成的节点

#### ```Strategy```中的关键步骤
因为我并不是每次都需要重新建树，所以会判断根节点的儿子中是否有对手选择落子的那一列，如果有的话就让根节点为该儿子节点，否则清空整个树。
之后令Node的指针指向根节点。执行下列过程：
1. 如果该胜负已定则直接向上更新root的祖先信息； 
2. 如果root胜负未定并且孩子尚未扩展完毕，就扩展root并对root的孩子进行模拟棋局，之后向上更新root的祖先信息；
3. 如果root胜负未定并且孩子已经扩展完毕了就令root指向孩子中profit（即UCT1值）最大的那个节点，重复上述过程直至达到规定的时间；
4. 最后在根节点的孩子中选择profit最大的节点的那一列作为落子的列。

## 算法反思
在理解了算法后，我开始按照算法流程加以实现，不过遇到了几个问题值得思考。

### 参数 c 的选取问题
在根据公式 𝐼𝑗 = 𝑋̅𝑗 + 𝑐·√(2ln(𝑛)/𝑇𝑗(𝑛)) 计算节点的 UCT1 时，有一个参数c可以调节。而 c 的作用就是在已经模拟多次的节点和模拟次数很少的节点中加以平衡，在调整中最终确定 c = 0.8时，对弈的胜率相对较高。

### 节点的扩展问题
维基百科上对“扩展”过程的描述中说“可以一次扩展一个或多个子节点”。考虑到如果一次将所有儿子节点扩展出来但只选择一个儿子进行模拟对局的话，其余儿子其实没有被利用到，会造成空间上的浪费，所以最终我每次只扩展一个儿子并对它进行模拟。

### 每次是否需要重新建树？
根据算法描述我们可以根据当前的棋盘状态构建一个根节点，并扩展出一颗搜索树，不过由于上一步的搜索信息其实可以被这一步的决策所利用，所以我并没有每步重新建树，而是在已经建好的树中移动根节点到当前状态。当然，这样做在具有保留了之前搜索信息的优点同时也有一定的缺点，那就是空间不够的问题。一开始我提前开好了 9900000 个结点，每走一步剩余可用的结点数都会减少。每次开始执行算法前都判断是否还有可用结点，如果没有的话就清空整个树，对当前棋局重新建树。在调试过程中我发现，如果剩余可用的结点数已经很少了，那么这一步扩展搜索树的过程就会因为结点数不够用的限制而导致搜索空间过小，从而无法给出较为合理的决策。所以，后来我不再等到可用结点用完后才清空树，而是一旦发现可用结点数小于 500000 时就清空树，这样就保证了每一步搜索至少可以在搜索树上新创建 500000 个结点，保证了这一步决策的可靠性。

### 随机模拟过程
在模拟棋局的过程中，rand()%N 的随机方法可以随机给出一列，并判断这一列是否可以落子。但是如果棋局可以落子的列已经很少了，那随机到这列的概率就很低，会出现长时间无法随机出这一列的情况。可以通过存储已经探索过的列来避免。

## AI效果测试
为了验证我写出的 AI 的水平，我使用 Compete.exe 让 AI 同 2-100.dll 分别对战1个回合（每个回合两局，双方各先手一局），最后统计 50 个回合（100 局）的胜率。一共进行了 10 次这样的测试，胜率分别为 93%，96%，98%，94%，93%，100%，92%，95%，92%，94%，最终平均胜率为 94.7%。

## 小结
通过本次实验，我加深了对蒙特卡罗搜索树和信心上限树算法的理解，利用这个算法实现了四子棋对弈的AI并取得了不错的效果，是一次让我收获颇丰、受益匪浅的实验。通过查阅相关文献以及和身边同学的交流，我思考并学到了不少新的知识，虽然最后AI不能保证 100%战胜所有的样例AI，但这已经是我充分努力后的结果。在之后的学习生活中，我会继续争取优化自己的AI，力求获得更大的进步，学习并掌握更多人工智能方面的知识。最后，这次实验的完成不仅提升了我的代码能力和调试能力，还让我对人工智能形成了更为全面的认识。

> copyright ©️清华大学美术学院信息艺术设计系（交叉学科） 美研171 宣程 2017213554
